{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment for Week 3 - Naive-Bayes\n",
    "\n",
    "### Task 1 - Bayesian Classification\n",
    "\n",
    "**Important Note:**\n",
    "This exercise is not a programming exercise, it is a math exercise to help reinforce the math behind a Bayesian Classification.  You can fill free to complete this in any method you feel is appropriate (ie: pencil/paper (you will need to scan your work to submit), Excel workbook, markdown text with a jupyter notebook, etc)<br>\n",
    "\n",
    "Please show all your work.\n",
    "\n",
    "1. In a study of pleas and prison sentences, it is reported that 42% of the subjects were sent to prison. Among those sent to prison, 38% plead guilty. Among those not sent to prison, 50% plead guilty.<br>\n",
    "&emsp;a) If a subject is randomly selected, what is the probability of getting a person who was not sent to prison? <br>\n",
    "&emsp;b) If a subject is randomly selected, and it is known that the subject entered a quilty plea, what is the probability that this subject was not sent to prison? <br>\n",
    "&emsp;c) If a subject is randomly selected, what is the probability of getting someone who was sent to prison?<br>\n",
    "&emsp;d) If a subject is randomly selected, and it is known that the subject entered a guilty plea, what is the probability that this person was sent to prison?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayes Theorem:\n",
    "The probability of event A, given that event B has subsequently occurred can be defined as \n",
    "\n",
    "$$\n",
    "P(A~|~B) = \\frac{P(A) \\cdot P(B~|~A)}{(~P(A) \\cdot P(B~|A~)~) + (~P(A') \\cdot P(B~|A'~)~)}\n",
    "$$\n",
    "\n",
    "**Note:** P(A')denotes P(not A) and the same applies for P(B').\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What we know at this point\n",
    "&emsp;&emsp;Let **A** be the event of **sent to prison**.\n",
    "\n",
    "$$ P(A) = .42 $$\n",
    "\n",
    "$$ P(A') = .58 $$\n",
    "\n",
    " Let **B** be the event of **entering a quilty plea**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Continue defining the probabilites and compute b-d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For assumption's sake, I'm going to use a hypothetical total of 100,000 individuals. Per the information provided: <br>\n",
    "Prevalence-42% sent to prison <br>\n",
    "Sensitivity-38% plead guilty & were sent to prison <br>\n",
    "False negatives-50% plead guilty & weren't sent to prison <br>\n",
    "\n",
    "People sent to prison = 42% of 100,000 = 42,000 <br>\n",
    "True positives (guilty & in prison) = 38% of 42,000 = 15,960 <br>\n",
    "False positives (not guilty & in prison) = 42,000-15,960 = 26,040 <br>\n",
    "Not sent to prison = 58% of 100,000 = 58,000 <br>\n",
    "True negatives (not guilty & not in prison) = 50% of 58,000 = 33,640 <br>\n",
    "False negatives (guilty & not in prison) = 58,000-33,640 = 24,360 <br>\n",
    "Pled guilty = 15,960 + 24,360 = 40,320 <br>\n",
    "Pled not guilty = 26,040 + 33,640 = 59,680 <br>\n",
    "Total= 40,320 + 59,680 = 100,000 <br>\n",
    "\n",
    "1a) 1-.42 = .58. 58% probability of a person being selected who wasn't sent to prison. <br>\n",
    "\n",
    "1b) 24,360/40,320 = 60.4% probability someone who entered a guilty plea was not sent to prison. <br>\n",
    "\n",
    "1c) 42% probability of selecting someone who was sent to prison. <br>\n",
    "\n",
    "1d) 15,960/40,320 = 39.58% probability of someone who entered a guilty plea was sent to prison. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Given the following table:\n",
    "\n",
    "|Customer ID| Gender  |Car Type|Shirt Size |Class|\n",
    "|:---------:|:-------:|:------:|:---------:|:---:|\n",
    "|1          |M        |Family  |Small      |CO   |\n",
    "|2          |M        |Sports  |Medium     |CO   |\n",
    "|3          |M        |Sports  |Medium     |CO   |\n",
    "|4          |M        |Sports  |Large      |CO   |\n",
    "|5          |M        |Sports  |Extra Large|CO   |\n",
    "|6          |M        |Sports  |Extra Large|CO   |\n",
    "|7          |F        |Sports  |Small      |CO   |\n",
    "|8          |F        |Sports  |Small      |CO   |\n",
    "|9          |F        |Sports  |Medium     |CO   |\n",
    "|10         |F        |Luxury  |Large      |CO   |\n",
    "|11         |M        |Family  |Large      |C1   |\n",
    "|12         |M        |Family  |Extra Large|C1   |\n",
    "|13         |M        |Family  |Medium     |C1   |\n",
    "|14         |M        |Luxury  |Extra Large|C1   |\n",
    "|15         |F        |Luxury  |Small      |C1   |\n",
    "|16         |F        |Luxury  |Small      |C1   |\n",
    "|17         |F        |Luxury  |Medium     |C1   |\n",
    "|18         |F        |Luxury  |Medium     |C1   |\n",
    "|19         |F        |Luxury  |Medium     |C1   |\n",
    "|20         |F        |Luxury  |Large      |C1   |\n",
    "<br>\n",
    "\n",
    "&emsp;a) What is the value of each of the following probabilities?<br>\n",
    "&emsp;   - P(Gender=M | Class=C0)<br>\n",
    "&emsp;   - P(Gender=F | Class=C1)<br>\n",
    "&emsp;   - P(Car Type=Family | Class=C0)<br>\n",
    "&emsp;   - P(Car Type=Family | Class=C1)<br>\n",
    "&emsp;   - P(Shirt Size=Medium | Class=C0)<br>\n",
    "&emsp;   - P(Shirt Size=Medium | Class=C1)<br>\n",
    "<br>\n",
    "&emsp;b) Use Naive Bayes Classifier to find the class of P(Gender=F | Car Type=Family| Shirt Size=Medium)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) <br>\n",
    "- P(Gender=M | Class=C0) = P(C0 | M) * P(M)/P(C0) <br>\n",
    "P(C0 | M) = 6/10 = 0.6, P(M) = 10/20 = 0.5, P(C0) = 10/20 = 0.5 <br>\n",
    "P(M | C0) = 0.6 * 0.5/0.5 = 0.60 <br>\n",
    "- P(Gender=F | Class=C1) = P(C1 | F) * P(F)/P(C1) <br>\n",
    "P(C1 | F) = 6/10 = 0.6, P(F) = 10/20 = 0.5, P(C1) = 10/20 = 0.5 <br>\n",
    "P(F | C1) = 0.6 * 0.5/0.5 = 0.60 <br>\n",
    "- P(Car Type=Family | Class=C0) = P(C0 | Family) * P(Family)/P(C0) <br>\n",
    "P(C0 | Family) = 1/10 = 0.1, P(C0) = 10/20 = 0.5, P(Family) = 4/20 = 0.2 <br>\n",
    "P(Family | C0) = 0.1 * 0.2/0.5 = 0.04 <br>\n",
    "- P(Car Type=Family | Class=C1) = P(C1 | Family) * P(Family)/P(C1) <br>\n",
    "P(C1 | Family) = 3/10 = 0.3, P(C1) = 10/20 = 0.5, P(Family) = 4/20 = 0.2 <br>\n",
    "P(Family | C1) = 0.3 * 0.2/0.5 = 0.12 <br>\n",
    "- P(Shirt Size=Medium | Class=C0) = P(C0 | Medium) * P(Medium)/P(C0) <br>\n",
    "P(C0 | Medium) = 3/10 = 0.3, P(C0) = 10/20 = 0.5, P(Medium) = 7/20 = 0.35 <br>\n",
    "P(Medium | C0) = 0.3 * 0.35/0.5 = 0.21 <br>\n",
    "- P(Shirt Size=Medium | Class=C1) = P(C1 | Medium) * P(Medium)/P(C0) <br>\n",
    "P(C1 | Medium) = 4/10 = 0.4, P(C1) = 10/20 = 0.5, P(Medium) = 7/20 = 0.35 <br>\n",
    "P(Medium | C1) = 0.4 * 0.35/0.5 = 0.28 <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Use Naive Bayes Classifier to find the class of P(Gender=F | Car Type=Family| Shirt Size=Medium)<br>\n",
    " - P(C0/(F/Family/Medium)) = P(C0) * P(F|C0) * P(Family|C0) * (Medium|C0)<br>\n",
    " - P(C0) = 0.5<br>\n",
    " - P(F|C0) = 0.4<br>\n",
    " - P(Family|C0) = 0.1<br>\n",
    " - P(Medium|C0) = 0.3<br>\n",
    " - P(P(C0/(F/Family/Medium)) = 0.5 * 0.4 * 0.1 * 0.3 = 0.006<br>\n",
    " \n",
    " - P(C1/(F/Family/Medium)) = P(C1) * P(F|C1) * P(Family|C1) * (Medium|C1)<br>\n",
    " - P(C1) = 0.5<br>\n",
    " - P(F|C1) = 0.6<br>\n",
    " - P(Family|C1) = 0.3<br>\n",
    " - P(Medium|C1) = 0.4<br>\n",
    " - P(P(C1/(F/Family/Medium)) = 0.5 * 0.6 * 0.3 * 0.4 = 0.036<br>\n",
    " \n",
    " Per the above, the class of P(Gender=F | Car Type=Family| Shirt Size=Medium) is C1 (0.036 > 0.006)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Task 2 - Text Classification\n",
    "**Data Set:** spam.csv located at https://www.kaggle.com/uciml/sms-spam-collection-dataset/version/1 <br>\n",
    "**Note:** you might want to use `encoding of latin-1` when loading this file (https://www.kaggle.com/benvozza/spam-classification)\n",
    "\n",
    "**Objective:** to classify SMS message as spam or not spam (ham).\n",
    "\n",
    "From the given data set, use Naïve Bayes to classify the SMS message.\n",
    "The framework for text classification is briefly summarized here:\n",
    "* Transformation of your dataset(change to lower case, remove numbers, remove punctuation, stop words, white space, word stemming, etc.)\n",
    "* Document-Term-Matrix creation – matrix of word counts for each individual document in the matrix (e.g. documents as rows, words as columns or vice versa)\n",
    "* Text Analysis (e.g. word counts, visualizations using wordclouds)\n",
    "\n",
    "**Helpful links:**<br>\n",
    "https://machinelearningmastery.com/clean-text-machine-learning-python/ <br>\n",
    "http://textminingonline.com/dive-into-nltk-part-iv-stemming-and-lemmatization <br>\n",
    "https://machinelearningmastery.com/prepare-text-data-machine-learning\n",
    "\n",
    "**Analysis Questions:**<br>\n",
    "* What is the accuracy of the model?  Report your finding with corresponding tables/graphs.\n",
    "* Print the 5 most frequent words in each class, and their posterior probability generated by the model.\n",
    "* How would you improve the model performance?\n",
    "* If the data set is bigger, do you think the accuracy increases? Discuss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB\n",
    "import string\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('assign_wk3/spam.csv',encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spam</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ham</td>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spam</td>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2 Unnamed: 2  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "5  spam  FreeMsg Hey there darling it's been 3 week's n...        NaN   \n",
       "6   ham  Even my brother is not like to speak with me. ...        NaN   \n",
       "7   ham  As per your request 'Melle Melle (Oru Minnamin...        NaN   \n",
       "8  spam  WINNER!! As a valued network customer you have...        NaN   \n",
       "9  spam  Had your mobile 11 months or more? U R entitle...        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4  \n",
       "0        NaN        NaN  \n",
       "1        NaN        NaN  \n",
       "2        NaN        NaN  \n",
       "3        NaN        NaN  \n",
       "4        NaN        NaN  \n",
       "5        NaN        NaN  \n",
       "6        NaN        NaN  \n",
       "7        NaN        NaN  \n",
       "8        NaN        NaN  \n",
       "9        NaN        NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   v1          5572 non-null   object\n",
      " 1   v2          5572 non-null   object\n",
      " 2   Unnamed: 2  50 non-null     object\n",
      " 3   Unnamed: 3  12 non-null     object\n",
      " 4   Unnamed: 4  6 non-null      object\n",
      "dtypes: object(5)\n",
      "memory usage: 217.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per the overwhelming amt of null values in the last 3 variables, I'm going to drop them from the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping clumns that we will not use\n",
    "df=df[[ \"v1\",\"v2\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Renaming remaining 2 variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'v1': 'Category', 'v2': 'text'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spam</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ham</td>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spam</td>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Category                                               text\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "5     spam  FreeMsg Hey there darling it's been 3 week's n...\n",
       "6      ham  Even my brother is not like to speak with me. ...\n",
       "7      ham  As per your request 'Melle Melle (Oru Minnamin...\n",
       "8     spam  WINNER!! As a valued network customer you have...\n",
       "9     spam  Had your mobile 11 months or more? U R entitle..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code blocks 24-29 are adapted from https://www.kaggle.com/benvozza/spam-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>text</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Category                                               text  length\n",
       "0      ham  Go until jurong point, crazy.. Available only ...     111\n",
       "1      ham                      Ok lar... Joking wif u oni...      29\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...     155\n",
       "3      ham  U dun say so early hor... U c already then say...      49\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...      61"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['length'] = df['text'].apply(len)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(text):\n",
    "    \n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    text = [word for word in text.split() if word.lower() not in stopwords.words('english')]\n",
    "    words = \"\"\n",
    "    for i in text:\n",
    "            stemmer = SnowballStemmer(\"english\")\n",
    "            words += (stemmer.stem(i))+\" \"\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "textFeatures = df['text'].copy()\n",
    "textFeatures = textFeatures.apply(pre_process)\n",
    "vectorizer = TfidfVectorizer(\"english\")\n",
    "features = vectorizer.fit_transform(textFeatures)\n",
    "\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(features, df['Category'], test_size=0.3, random_state=111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-ff57fab6a553>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmatrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'text' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'counts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-96b09cf5e69e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcounts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'counts' is not defined"
     ]
    }
   ],
   "source": [
    "counts.T.sort_values(by=0, ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9850478468899522"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "mnb = MultinomialNB(alpha=0.2)\n",
    "mnb.fit(features_train, labels_train)\n",
    "prediction = mnb.predict(features_test)\n",
    "accuracy_score(labels_test,prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to use this data for machine learning, we need to be able to convert the content of each string into a vector of numbers. For this we will use the TF-IDF vectorizer (discussed in Feature Engineering), and create a pipeline that attaches it to a multinomial naive Bayes classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "model = make_pipeline(TfidfVectorizer(), MultinomialNB())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'target'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-f474bbae7d15>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5137\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5138\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5139\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5141\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Series' object has no attribute 'target'"
     ]
    }
   ],
   "source": [
    "model.fit(features_train.data, labels_train.target)\n",
    "labels = model.predict(features_test.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deliverables:\n",
    "\n",
    "Upload your work from task 1 and your notebook from task 2\n",
    "   \n",
    "**Important:** Make sure your provide complete and thorough explanations for all of your analysis. You need to defend your thought processes and reasoning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
