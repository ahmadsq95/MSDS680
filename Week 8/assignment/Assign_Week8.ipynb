{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment for  Week 8 - Reinforcement Learning\n",
    "\n",
    "### Q-Learning\n",
    "\n",
    "**Objective:**\n",
    "Reproduce the exercise explained in the following tutorial videos: <br>\n",
    "\n",
    "* https://www.youtube.com/watch?v=yMk_XtIEzH8&list=PLQVvvaa0QuDezJFIOU5wDdfy4e9vdnx-7 <br>\n",
    "* https://www.youtube.com/watch?v=Gq1Azv_B4-4 <br>\n",
    "* https://www.youtube.com/watch?v=CBTbifYx6a8 <br>\n",
    "\n",
    "These videos are accompanied by the following:.  \n",
    "* [Q-Learning introduction and Q Table - Reinforcement Learning w/ Python Tutorial p.1](https://pythonprogramming.net/q-learning-reinforcement-learning-python-tutorial/) <br>\n",
    "* [Q-Learning introduction and Q Table - Reinforcement Learning w/ Python Tutorial p.2](https://pythonprogramming.net/q-learning-algorithm-reinforcement-learning-python-tutorial/?completed=/q-learning-reinforcement-learning-python-tutorial/) <br>\n",
    "* [Q-Learning introduction and Q Table - Reinforcement Learning w/ Python Tutorial p.3](https://pythonprogramming.net/q-learning-analysis-reinforcement-learning-python-tutorial/?completed=/q-learning-algorithm-reinforcement-learning-python-tutorial/) <br>\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Important::</b> In working through the code listed on the webpages, there are a number of errors that prevent the demo from performing correctly.  The code shown in the videos is correct!\n",
    "</div>\n",
    "\n",
    "**NOTE:** You don't need to reproduce all of the graphs demostrated in the third video for this assignment. Please include 2 of the demonstrated graphs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deliverables:\n",
    "\n",
    "Upload your notebook's .ipynb file, a pdf printout and a screenshot of your car reaching it's goal.\n",
    "   \n",
    "**Important:** Make sure your provide complete and thorough explanations for all of your analysis. You need to defend your thought processes and reasoning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import pyglet\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    First Video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6  0.07]\n",
      "[-1.2  -0.07]\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"MountainCar-v0\")\n",
    "env.reset()\n",
    "done = False\n",
    "\n",
    "print(env.observation_space.high)\n",
    "print(env.observation_space.low)\n",
    "print(env.action_space.n)\n",
    "\n",
    "discrete_os_size = [20] * len(env.observation_space.high)\n",
    "discrete_os_win_size = (env.observation_space.high - env.observation_space.low) / discrete_os_size\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "q_table = np.random.uniform(low=-2, high=0, size = (discrete_os_size + [env.action_space.n]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Second video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()\n",
    "done = False\n",
    "\n",
    "learning_rate = 0.1\n",
    "discount = 0.95\n",
    "episodes = 25000\n",
    "\n",
    "discrete_os_size = [20] * len(env.observation_space.high)\n",
    "discrete_os_win_size = (env.observation_space.high - env.observation_space.low) / discrete_os_size\n",
    "\n",
    "\n",
    "def get_discrete_state(state):\n",
    "    discrete_state = (state - env.observation_space.low) / discrete_os_win_size\n",
    "    return tuple(discrete_state.astype(np.int32))\n",
    "\n",
    "discrete_state = get_discrete_state(env.reset())\n",
    "\n",
    "\n",
    "#print(discrete_state)\n",
    "#print(np.argmax(q_table[discrete_state]))\n",
    "\n",
    "\n",
    "while not done:\n",
    "    action = np.argmax(q_table[discrete_state])\n",
    "    new_state, reward, done, _ = env.step(action)\n",
    "    new_discrete_state = get_discrete_state(new_state)\n",
    "    env.render()\n",
    "    if not done:\n",
    "        max_feature_q = np.max(q_table[new_discrete_state])\n",
    "        current_q = q_table[discrete_state + (action,)]\n",
    "        new_q = (1 - learning_rate) * current_q + learning_rate * (reward + discount * max_feature_q)\n",
    "        q_table[discrete_state+(action, )] = new_q\n",
    "    elif new_state[0] >= env.goal_position:\n",
    "        q_table[discrete_state + (action, )] = 0 \n",
    "        \n",
    "    discerete_state = new_discrete_state\n",
    "    \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2000\n",
      "4000\n",
      "6000\n",
      "8000\n",
      "10000\n",
      "12000\n",
      "14000\n",
      "16000\n",
      "18000\n",
      "20000\n",
      "22000\n",
      "24000\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "done = False\n",
    "\n",
    "learning_rate = 0.1\n",
    "discount = 0.95\n",
    "episodes = 25000\n",
    "\n",
    "show_every = 2000\n",
    "\n",
    "discrete_os_size = [20] * len(env.observation_space.high)\n",
    "discrete_os_win_size = (env.observation_space.high - env.observation_space.low) / discrete_os_size\n",
    "\n",
    "\n",
    "def get_discrete_state(state):\n",
    "    discrete_state = (state - env.observation_space.low) / discrete_os_win_size\n",
    "    return tuple(discrete_state.astype(np.int32))\n",
    "\n",
    "\n",
    "for episode in range(episodes):\n",
    "    if episode % show_every == 0:\n",
    "        render = True\n",
    "        print(episode)\n",
    "    else:\n",
    "        render = False\n",
    "    discrete_state = get_discrete_state(env.reset())\n",
    "    while not done:\n",
    "        action = np.argmax(q_table[discrete_state])\n",
    "        new_state, reward, done, _ = env.step(action)\n",
    "        new_discrete_state = get_discrete_state(new_state)\n",
    "        if render:\n",
    "            env.render()\n",
    "        if not done:\n",
    "            max_feature_q = np.max(q_table[new_discrete_state])\n",
    "            current_q = q_table[discrete_state + (action,)]\n",
    "            new_q = (1 - learning_rate) * current_q + learning_rate * (reward + discount * max_feature_q)\n",
    "            q_table[discrete_state+(action, )] = new_q\n",
    "        elif new_state[0] >= env.goal_position:\n",
    "            print(\"We made it on episode: \", episode)\n",
    "            q_table[discrete_state + (action, )] = 0 \n",
    "\n",
    "        discerete_state = new_discrete_state\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Interesting, sometimes the car reach the goal, sometime it does not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2000\n",
      "4000\n",
      "6000\n",
      "8000\n",
      "10000\n",
      "12000\n",
      "14000\n",
      "16000\n",
      "18000\n",
      "20000\n",
      "22000\n",
      "24000\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "done = False\n",
    "\n",
    "learning_rate = 0.1\n",
    "discount = 0.95\n",
    "episodes = 25000\n",
    "\n",
    "show_every = 2000\n",
    "\n",
    "discrete_os_size = [20] * len(env.observation_space.high)\n",
    "discrete_os_win_size = (env.observation_space.high - env.observation_space.low) / discrete_os_size\n",
    "\n",
    "\n",
    "epsilon = 0.5\n",
    "start_epsilon_decaying = 1\n",
    "end_epsilon_decaying = episodes // 2 \n",
    "epsilon_decay_value = epsilon / (end_epsilon_decaying - start_epsilon_decaying)\n",
    "\n",
    "def get_discrete_state(state):\n",
    "    discrete_state = (state - env.observation_space.low) / discrete_os_win_size\n",
    "    return tuple(discrete_state.astype(np.int32))\n",
    "\n",
    "\n",
    "for episode in range(episodes):\n",
    "    if episode % show_every == 0:\n",
    "        render = True\n",
    "        print(episode)\n",
    "    else:\n",
    "        render = False\n",
    "    discrete_state = get_discrete_state(env.reset())\n",
    "    while not done:\n",
    "        if np.random.random() > epsilon:\n",
    "            action = np.argmax(q_table[discrete_state])\n",
    "        else:\n",
    "            action = np.random.randint(0, env.action_space.n)\n",
    "        new_state, reward, done, _ = env.step(action)\n",
    "        new_discrete_state = get_discrete_state(new_state)\n",
    "        if render:\n",
    "            env.render()\n",
    "        if not done:\n",
    "            max_feature_q = np.max(q_table[new_discrete_state])\n",
    "            current_q = q_table[discrete_state + (action,)]\n",
    "            new_q = (1 - learning_rate) * current_q + learning_rate * (reward + discount * max_feature_q)\n",
    "            q_table[discrete_state+(action, )] = new_q\n",
    "        elif new_state[0] >= env.goal_position:\n",
    "            print(\"We made it on episode: \", episode)\n",
    "            q_table[discrete_state + (action, )] = 0 \n",
    "\n",
    "        discerete_state = new_discrete_state\n",
    "    \n",
    "    if end_epsilon_decaying >= episode >= start_epsilon_decaying:\n",
    "        epsilon -= epsilon_decay_value\n",
    "    \n",
    "    \n",
    "    \n",
    "env.close() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Third video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Episode:  0 Avg:  -200.0 Min:  -200.0 Max:  -200.0\n",
      "500\n",
      "Episode:  500 Avg:  0.0 Min:  0 Max:  0\n",
      "1000\n",
      "Episode:  1000 Avg:  0.0 Min:  0 Max:  0\n",
      "1500\n",
      "Episode:  1500 Avg:  0.0 Min:  0 Max:  0\n",
      "2000\n",
      "Episode:  2000 Avg:  0.0 Min:  0 Max:  0\n",
      "2500\n",
      "Episode:  2500 Avg:  0.0 Min:  0 Max:  0\n",
      "3000\n",
      "Episode:  3000 Avg:  0.0 Min:  0 Max:  0\n",
      "3500\n",
      "Episode:  3500 Avg:  0.0 Min:  0 Max:  0\n",
      "4000\n",
      "Episode:  4000 Avg:  0.0 Min:  0 Max:  0\n",
      "4500\n",
      "Episode:  4500 Avg:  0.0 Min:  0 Max:  0\n",
      "5000\n",
      "Episode:  5000 Avg:  0.0 Min:  0 Max:  0\n",
      "5500\n",
      "Episode:  5500 Avg:  0.0 Min:  0 Max:  0\n",
      "6000\n",
      "Episode:  6000 Avg:  0.0 Min:  0 Max:  0\n",
      "6500\n",
      "Episode:  6500 Avg:  0.0 Min:  0 Max:  0\n",
      "7000\n",
      "Episode:  7000 Avg:  0.0 Min:  0 Max:  0\n",
      "7500\n",
      "Episode:  7500 Avg:  0.0 Min:  0 Max:  0\n",
      "8000\n",
      "Episode:  8000 Avg:  0.0 Min:  0 Max:  0\n",
      "8500\n",
      "Episode:  8500 Avg:  0.0 Min:  0 Max:  0\n",
      "9000\n",
      "Episode:  9000 Avg:  0.0 Min:  0 Max:  0\n",
      "9500\n",
      "Episode:  9500 Avg:  0.0 Min:  0 Max:  0\n",
      "10000\n",
      "Episode:  10000 Avg:  0.0 Min:  0 Max:  0\n",
      "10500\n",
      "Episode:  10500 Avg:  0.0 Min:  0 Max:  0\n",
      "11000\n",
      "Episode:  11000 Avg:  0.0 Min:  0 Max:  0\n",
      "11500\n",
      "Episode:  11500 Avg:  0.0 Min:  0 Max:  0\n",
      "12000\n",
      "Episode:  12000 Avg:  0.0 Min:  0 Max:  0\n",
      "12500\n",
      "Episode:  12500 Avg:  0.0 Min:  0 Max:  0\n",
      "13000\n",
      "Episode:  13000 Avg:  0.0 Min:  0 Max:  0\n",
      "13500\n",
      "Episode:  13500 Avg:  0.0 Min:  0 Max:  0\n",
      "14000\n",
      "Episode:  14000 Avg:  0.0 Min:  0 Max:  0\n",
      "14500\n",
      "Episode:  14500 Avg:  0.0 Min:  0 Max:  0\n",
      "15000\n",
      "Episode:  15000 Avg:  0.0 Min:  0 Max:  0\n",
      "15500\n",
      "Episode:  15500 Avg:  0.0 Min:  0 Max:  0\n",
      "16000\n",
      "Episode:  16000 Avg:  0.0 Min:  0 Max:  0\n",
      "16500\n",
      "Episode:  16500 Avg:  0.0 Min:  0 Max:  0\n",
      "17000\n",
      "Episode:  17000 Avg:  0.0 Min:  0 Max:  0\n",
      "17500\n",
      "Episode:  17500 Avg:  0.0 Min:  0 Max:  0\n",
      "18000\n",
      "Episode:  18000 Avg:  0.0 Min:  0 Max:  0\n",
      "18500\n",
      "Episode:  18500 Avg:  0.0 Min:  0 Max:  0\n",
      "19000\n",
      "Episode:  19000 Avg:  0.0 Min:  0 Max:  0\n",
      "19500\n",
      "Episode:  19500 Avg:  0.0 Min:  0 Max:  0\n",
      "20000\n",
      "Episode:  20000 Avg:  0.0 Min:  0 Max:  0\n",
      "20500\n",
      "Episode:  20500 Avg:  0.0 Min:  0 Max:  0\n",
      "21000\n",
      "Episode:  21000 Avg:  0.0 Min:  0 Max:  0\n",
      "21500\n",
      "Episode:  21500 Avg:  0.0 Min:  0 Max:  0\n",
      "22000\n",
      "Episode:  22000 Avg:  0.0 Min:  0 Max:  0\n",
      "22500\n",
      "Episode:  22500 Avg:  0.0 Min:  0 Max:  0\n",
      "23000\n",
      "Episode:  23000 Avg:  0.0 Min:  0 Max:  0\n",
      "23500\n",
      "Episode:  23500 Avg:  0.0 Min:  0 Max:  0\n",
      "24000\n",
      "Episode:  24000 Avg:  0.0 Min:  0 Max:  0\n",
      "24500\n",
      "Episode:  24500 Avg:  0.0 Min:  0 Max:  0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "env.reset()\n",
    "done = False\n",
    "\n",
    "learning_rate = 0.1\n",
    "discount = 0.95\n",
    "episodes = 25000\n",
    "\n",
    "show_every = 500\n",
    "\n",
    "discrete_os_size = [20] * len(env.observation_space.high)\n",
    "discrete_os_win_size = (env.observation_space.high - env.observation_space.low) / discrete_os_size\n",
    "\n",
    "\n",
    "epsilon = 0.5\n",
    "start_epsilon_decaying = 1\n",
    "end_epsilon_decaying = episodes // 2 \n",
    "epsilon_decay_value = epsilon / (end_epsilon_decaying - start_epsilon_decaying)\n",
    "\n",
    "\n",
    "ep_rewards = []\n",
    "aggr_ep_rewards = {'ep' : [] ,'avg' : [] , 'min' : [] , 'max' : []}\n",
    "\n",
    "def get_discrete_state(state):\n",
    "    discrete_state = (state - env.observation_space.low) / discrete_os_win_size\n",
    "    return tuple(discrete_state.astype(np.int32))\n",
    "\n",
    "\n",
    "for episode in range(episodes):\n",
    "    episode_reward = 0 \n",
    "    if episode % show_every == 0:\n",
    "        render = True\n",
    "        print(episode)\n",
    "    else:\n",
    "        render = False\n",
    "    discrete_state = get_discrete_state(env.reset())\n",
    "    while not done:\n",
    "        if np.random.random() > epsilon:\n",
    "            action = np.argmax(q_table[discrete_state])\n",
    "        else:\n",
    "            action = np.random.randint(0, env.action_space.n)\n",
    "        new_state, reward, done, _ = env.step(action)\n",
    "        episode_reward += reward\n",
    "        new_discrete_state = get_discrete_state(new_state)\n",
    "        if render:\n",
    "            env.render()\n",
    "        if not done:\n",
    "            max_feature_q = np.max(q_table[new_discrete_state])\n",
    "            current_q = q_table[discrete_state + (action,)]\n",
    "            new_q = (1 - learning_rate) * current_q + learning_rate * (reward + discount * max_feature_q)\n",
    "            q_table[discrete_state+(action, )] = new_q\n",
    "        elif new_state[0] >= env.goal_position:\n",
    "            print(\"We made it on episode: \", episode)\n",
    "            q_table[discrete_state + (action, )] = 0 \n",
    "\n",
    "        discerete_state = new_discrete_state\n",
    "    \n",
    "    if end_epsilon_decaying >= episode >= start_epsilon_decaying:\n",
    "        epsilon -= epsilon_decay_value\n",
    "    \n",
    "    \n",
    "    ep_rewards.append(episode_reward)\n",
    "    if not episode % show_every:\n",
    "        average_reward = sum(ep_rewards[-show_every:])/len(ep_rewards[-show_every:])\n",
    "        aggr_ep_rewards['ep'].append(episode)\n",
    "        aggr_ep_rewards['avg'].append(average_reward)\n",
    "        aggr_ep_rewards['min'].append(min(ep_rewards[-show_every:]))\n",
    "        aggr_ep_rewards['max'].append(max(ep_rewards[-show_every:]))\n",
    "        print('Episode: ',episode ,'Avg: ',average_reward , 'Min: ' ,min(ep_rewards[-show_every:]), 'Max: ',max(ep_rewards[-show_every:]))\n",
    "    \n",
    "    \n",
    "env.close() \n",
    "\n",
    "plt.plot(aggr_ep_rewards['ep'],aggr_ep_rewards['avg'], label='Avg')\n",
    "plt.plot(aggr_ep_rewards['ep'],aggr_ep_rewards['min'], label='min')\n",
    "plt.plot(aggr_ep_rewards['ep'],aggr_ep_rewards['max'], label='max')\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Due to high randomness, the car reached the goal once, and it failed to reach the goal every time. I am not sure if that's because of learning rate, discount, or number of episode is not enough for the model to learn. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### References \n",
    "\n",
    "https://www.youtube.com/watch?v=yMk_XtIEzH8&list=PLQVvvaa0QuDezJFIOU5wDdfy4e9vdnx-7\n",
    "\n",
    "https://www.youtube.com/watch?v=Gq1Azv_B4-4\n",
    "\n",
    "https://www.youtube.com/watch?v=CBTbifYx6a8"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
